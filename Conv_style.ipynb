{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "z_size = 32\n",
    "batch_size = 100\n",
    "mnist = input_data.read_data_sets('../MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def encoder(inputs):\n",
    "    '''\n",
    "        input :\n",
    "            inputs [None, 784]\n",
    "        return :\n",
    "            mu, sigma\n",
    "    '''\n",
    "    Encoder = {}\n",
    "    with tf.variable_scope(\"Encoder\"):\n",
    "        Encoder['inputs_reshape'] = tf.reshape(inputs, [-1,28,28,1])\n",
    "        with tf.variable_scope('conv1'):\n",
    "            Encoder['conv1'] = convolution(Encoder['inputs_reshape'], 5, 5, 1, 8)\n",
    "            Encoder['pool1'] = tf.nn.max_pool(Encoder['conv1'], ksize=[1,2,2,1] ,strides=[1,2,2,1],padding = 'SAME')\n",
    "        with tf.variable_scope('conv2'):\n",
    "            Encoder['conv2'] = convolution(Encoder['pool1'], 5, 5, 8, 16)\n",
    "            Encoder['pool2'] = tf.nn.max_pool(Encoder['conv2'], ksize=[1,2,2,1] ,strides=[1,2,2,1],padding = 'SAME')\n",
    "        with tf.variable_scope('conv3'):\n",
    "            Encoder['conv3'] = convolution(Encoder['pool2'], 3, 3, 16, 16)\n",
    "        Encoder['conv3_reshape'] = tf.reshape(Encoder['conv3'], [batch_size, 2*2*16])\n",
    "        with tf.variable_scope('mu'):\n",
    "            Encoder['mu'] = fully_connected(Encoder['conv3_reshape'], 2*2*16, z_size)\n",
    "        with tf.variable_scope('sigma'):\n",
    "            Encoder['sigma'] = tf.nn.elu(fully_connected(Encoder['conv3_reshape'], 2*2*16, z_size)/2)\n",
    "        return Encoder['mu'], Encoder['sigma']\n",
    "\n",
    "def sampling_z(z_mu, z_sigma):\n",
    "    return z_mu + z_sigma*np.random.randn(batch_size, z_size)\n",
    "\n",
    "def decoder(z_samples, reuse=False):\n",
    "    with tf.variable_scope(\"Decoder\") as scope:\n",
    "        if reuse: \n",
    "            scope.reuse_variables()\n",
    "        Decoder = {}\n",
    "        with tf.variable_scope(\"fc1\"):\n",
    "            Decoder['fc1'] = fully_connected(z_samples, z_size, 7*7*4)\n",
    "        Decoder['reshape1'] = tf.reshape(Decoder['fc1'], [batch_size,7,7,4])\n",
    "        with tf.variable_scope(\"deconv1\"):\n",
    "            Decoder['deconv1'] = tf.nn.elu(deconvolution(Decoder['reshape1'], \n",
    "                                                         [3, 3, 2, 4],\n",
    "                                                         [1, 2, 2, 1],\n",
    "                                                         [batch_size, 14, 14, 2]))\n",
    "        with tf.variable_scope(\"deconv2\"):\n",
    "            Decoder['deconv2'] = deconvolution(Decoder['deconv1'],\n",
    "                                                         [3, 3, 1, 2],\n",
    "                                                         [1, 2, 2, 1],\n",
    "                                                         [batch_size, 28, 28, 1])     \n",
    "        \n",
    "        Decoder['logits'] = tf.reshape(Decoder['deconv2'], [batch_size, 28*28])\n",
    "        Decoder['probs'] = tf.sigmoid(Decoder['logits'])\n",
    "        return Decoder['logits'], Decoder['probs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [batch_size, 784])\n",
    "z_mu, z_sigma = encoder(x)\n",
    "z_samples = sampling_z(z_mu, z_sigma)\n",
    "logits, probs = decoder(z_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('loss'):\n",
    "    reconstruction_loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels= x))\n",
    "    KL_divergence_loss = 1/2 * tf.reduce_mean(z_sigma**2 + z_mu**2 - 1 - tf.log(z_sigma**2))\n",
    "    loss = tf.reduce_mean(reconstruction_loss + KL_divergence_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "trainer = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_batch = int(mnist.train.num_examples/batch_size)\n",
    "epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#train_X, train_ys = mnist.train.next_batch(batch_size)\n",
    "#print(\"z_mu : {}\".format(sess.run(z_mu, feed_dict={ x :train_X})))\n",
    "#print(\"z_sigma : {}\".format(sess.run(z_sigma, feed_dict={ x :train_X})))\n",
    "#print(\"z_samples : {}\".format(sess.run(z_samples, feed_dict={ x :train_X})))\n",
    "#print(\"logits : {}\".format(sess.run(logits, feed_dict={ x :train_X})))\n",
    "#print(\"probs : {}\".format(sess.run(probs, feed_dict={ x :train_X})))\n",
    "#print(\"reconst loss : {}\".format(sess.run(reconstruction_loss, feed_dict={ x :train_X})))\n",
    "#print(\"KL loss : {}\".format(sess.run(KL_divergence_loss, feed_dict={ x :train_X})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch(1/20) : cost= 2305.600996870561\n",
      "Epoch(2/20) : cost= 98.47263685746627\n",
      "Epoch(3/20) : cost= 10.963942235599864\n",
      "Epoch(4/20) : cost= 3.3029188056425616\n",
      "Epoch(5/20) : cost= 1.3252110403234307\n",
      "Epoch(6/20) : cost= 0.8906889675964008\n",
      "Epoch(7/20) : cost= 0.6827985392375426\n",
      "Epoch(8/20) : cost= 0.6571405708247965\n",
      "Epoch(9/20) : cost= 0.44796808995983817\n",
      "Epoch(10/20) : cost= 0.3536465325680646\n",
      "Epoch(11/20) : cost= 0.31936232127926567\n",
      "Epoch(12/20) : cost= 0.29766240244561976\n",
      "Epoch(13/20) : cost= 0.28455818485129963\n",
      "Epoch(14/20) : cost= 0.2780686438083649\n",
      "Epoch(15/20) : cost= 0.27423293520103803\n",
      "Epoch(16/20) : cost= 0.27323323862119153\n",
      "Epoch(17/20) : cost= 0.26949626218188893\n",
      "Epoch(18/20) : cost= 0.26775421064008365\n",
      "Epoch(19/20) : cost= 0.2665791111913594\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for _ in range(epoch):\n",
    "    avg_cost = 0\n",
    "    for nb in range(num_batch):\n",
    "        train_X, train_ys = mnist.train.next_batch(batch_size)\n",
    "        loss_get, train_ = sess.run([loss, trainer], feed_dict={ x :train_X})\n",
    "        avg_cost += loss_get\n",
    "\n",
    "    avg_cost/= num_batch\n",
    "    print(\"Epoch({}/{}) : cost= {}\".format(_+1, epoch, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "generated_z = np.random.normal(size=(batch_size, z_size)).astype(np.float32)\n",
    "_, probs = decoder(generated_z, reuse=True)\n",
    "images = np.reshape(sess.run(probs), [100, 28, 28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def square_plot(data):\n",
    "    if type(data) == list:\n",
    "        data = np.concatenate(data)\n",
    "    # normalize data for display\n",
    "    data = (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "    # force the number of filters to be square\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "\n",
    "    padding = (((0, n ** 2 - data.shape[0]) ,\n",
    "                (0, 1), (0, 1))  # add some space between filters\n",
    "               + ((0, 0),) * (data.ndim - 3))  # don't pad the last dimension (if there is one)\n",
    "    data = np.pad(data , padding, mode='constant' , constant_values=1)  # pad with ones (white)\n",
    "\n",
    "    # tilethe filters into an image\n",
    "    data = data.reshape((n , n) + data.shape[1:]).transpose((0 , 2 , 1 , 3) + tuple(range(4 , data.ndim + 1)))\n",
    "\n",
    "    data = data.reshape((n * data.shape[1] , n * data.shape[3]) + data.shape[4:])\n",
    "\n",
    "    fig = plt.figure(figsize=(17, 17))\n",
    "    plt.imshow(data[:,:,0], cmap='gray')\n",
    "    plt.axis('off')\n",
    "    plt.close()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig = square_plot(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
